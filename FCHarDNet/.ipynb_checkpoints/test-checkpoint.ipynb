{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bebc5ceed9f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from models import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state_dict(state_dict):\n",
    "    \"\"\"Converts a state dict saved from a dataParallel module to normal\n",
    "       module state_dict inplace\n",
    "       :param state_dict is the loaded DataParallel model_state\n",
    "    \"\"\"\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:]  # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict\n",
    "def decode_segmap(temp,label_colours):\n",
    "    r = temp.copy()\n",
    "    g = temp.copy()\n",
    "    b = temp.copy()\n",
    "    for l in range(0, 19):\n",
    "        r[temp == l] = label_colours[l][0]\n",
    "        g[temp == l] = label_colours[l][1]\n",
    "        b[temp == l] = label_colours[l][2]\n",
    "    print('hi')\n",
    "    rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n",
    "    rgb[:, :, 0] = r / 255.0\n",
    "    rgb[:, :, 1] = g / 255.0\n",
    "    rgb[:, :, 2] = b / 255.0\n",
    "    return rgb\n",
    "def init_model(model_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_classes = 19\n",
    "    # Setup Model\n",
    "    model = get_model({\"arch\": \"hardnet\"}, n_classes)\n",
    "    state = convert_state_dict(torch.load(model_path, map_location=device)[\"model_state\"])\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return device, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img, size, device, model):\n",
    "    #print(\"Read Input Image from : {}\".format(img_path))\n",
    "\n",
    "    img_resized = cv2.resize(img, (size[1], size[0]))  # uint8 with RGB mode\n",
    "    img = img_resized.astype(np.float16)\n",
    "\n",
    "    # norm\n",
    "    value_scale = 255\n",
    "    mean = [0.406, 0.456, 0.485]\n",
    "    mean = [item * value_scale for item in mean]\n",
    "    std = [0.225, 0.224, 0.229]\n",
    "    std = [item * value_scale for item in std]\n",
    "    img = (img - mean) / std\n",
    "\n",
    "    # NHWC -> NCHW\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    img = torch.from_numpy(img).float()\n",
    "\n",
    "    images = img.to(device)\n",
    "    outputs = model(images)\n",
    "    colors = [  # [  0,   0,   0],\n",
    "        [128, 64, 128],\n",
    "        [244, 35, 232],\n",
    "        [70, 70, 70],\n",
    "        [102, 102, 156],\n",
    "        [190, 153, 153],\n",
    "        [153, 153, 153],\n",
    "        [250, 170, 30],\n",
    "        [220, 220, 0],\n",
    "        [107, 142, 35],\n",
    "        [152, 251, 152],\n",
    "        [0, 130, 180],\n",
    "        [220, 20, 60],\n",
    "        [255, 0, 0],\n",
    "        [0, 0, 142],\n",
    "        [0, 0, 70],\n",
    "        [0, 60, 100],\n",
    "        [0, 80, 100],\n",
    "        [0, 0, 230],\n",
    "        [119, 11, 32],\n",
    "    ]\n",
    "    \n",
    "    label_colours = dict(zip(range(19), colors))\n",
    "    print('Output shape: ',outputs.shape)\n",
    "    pred = np.squeeze(outputs.data.max(1)[1].cpu().numpy(), axis=0)\n",
    "    print(pred.shape)\n",
    "    decoded = decode_segmap(temp=pred,label_colours=label_colours)\n",
    "    print(img_resized.shape)\n",
    "    print(decoded.shape)\n",
    "    \n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_segmendet_image(img, img_decoded):\n",
    "    print(\"result\")\n",
    "    image=img.astype(np.float32)/255.0\n",
    "    plt.imshow(np.concatenate((image, img_decoded), axis=0))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        #print(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = './data'\n",
    "images = load_images_from_folder(images_path)\n",
    "device,model = init_model(\"pretrained/hardnet70_cityscapes_model.pkl\")\n",
    "\n",
    "for image in images:\n",
    "    img_decoded = process_img(image,[375,1242],device,model.cuda())\n",
    "    plot_segmendet_image(image, img_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
